import pandas as pd
import numpy as np
import glob
import os
from sklearn.preprocessing import StandardScaler, LabelEncoder

# === è³‡æ–™ä¾†æºè¨­å®š ===
data_dir = "TestData"
merged_files = glob.glob(os.path.join(data_dir, "Splited_Merged0*.csv"))
print(f"æ‰¾åˆ° {len(merged_files)} å€‹æª”æ¡ˆï¼š", merged_files)

processed_data = []

# === è™•ç†æ¯å€‹æª”æ¡ˆ ===
for file in merged_files:
    print(f"è™•ç†æª”æ¡ˆ: {file}")
    try:
        df = pd.read_csv(file)

        # ç§»é™¤ infã€NaN
        df.replace([np.inf, -np.inf], np.nan, inplace=True)
        df.dropna(inplace=True)

        # === ğŸ” ç§»é™¤ç„¡ç”¨æ¬„ä½ ===
        drop_cols = ['Number', 'Tot sum', 'Tot size']
        df.drop(columns=drop_cols, errors='ignore', inplace=True)

        # Label ç·¨ç¢¼
        le = LabelEncoder()
        df['Label'] = le.fit_transform(df['Label'])

        # å„²å­˜ Label å°ç…§è¡¨ï¼ˆåªåšä¸€æ¬¡ï¼‰
        if not os.path.exists("label_map.csv"):
            label_map = dict(zip(le.classes_, le.transform(le.classes_)))
            pd.Series(label_map).to_csv("label_map.csv")
            print("âœ… å·²å„²å­˜ label_map.csv")

        # æ¨™æº–åŒ–ç‰¹å¾µæ¬„ä½
        X = df.drop('Label', axis=1)
        y = df['Label']
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        df_scaled = pd.DataFrame(X_scaled, columns=X.columns)
        df_scaled['Label'] = y.values

        processed_data.append(df_scaled)

    except Exception as e:
        print(f"âš ï¸ æª”æ¡ˆ {file} ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

# === åˆä½µæ‰€æœ‰è™•ç†å¾Œçš„è³‡æ–™ ===
final_df = pd.concat(processed_data, ignore_index=True)
print(f"åˆä½µå¾Œè³‡æ–™ç­†æ•¸ï¼š{len(final_df)}")

# === ğŸ” ç¯©é¸é¡åˆ¥ï¼šåˆªé™¤æ¨£æœ¬æ•¸ä¸è¶³ 3000ï¼Œéå¤šå‰‡ä¸‹æ¡æ¨£åˆ° 50000 ===
label_counts = final_df['Label'].value_counts()
print("\nğŸ“Š åŸå§‹é¡åˆ¥åˆ†å¸ƒï¼š")
print(label_counts.sort_index())

# åªä¿ç•™æ¨£æœ¬æ•¸ â‰¥ 3000 çš„é¡åˆ¥
valid_labels = label_counts[label_counts >= 3000].index
filtered_df = final_df[final_df['Label'].isin(valid_labels)].copy()

# å°æ¨£æœ¬æ•¸ > 100000 çš„é¡åˆ¥ä¸‹æ¡æ¨£åˆ° 50000
downsampled_df = filtered_df.groupby('Label').apply(
    lambda x: x.sample(n=50000, random_state=42) if len(x) > 100000 else x
).reset_index(drop=True)

# é¡¯ç¤ºè™•ç†å¾Œçš„é¡åˆ¥åˆ†å¸ƒ
print("\nğŸ“Š è™•ç†å¾Œé¡åˆ¥åˆ†å¸ƒï¼š")
print(downsampled_df['Label'].value_counts().sort_index())

# === è¼¸å‡ºçµæœ ===
downsampled_df.to_csv("processed_dataset_test.csv", index=False)
print("âœ… å·²å„²å­˜è™•ç†çµæœè‡³ processed_dataset.csv")
