# train_dnn_smote.py
import pandas as pd
import numpy as np
import joblib
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
import seaborn as sns

# === åƒæ•¸è¨­å®š ===
DATA_FILE = "processed_dataset.csv"  # åŸå§‹è³‡æ–™ï¼ˆä¸å¹³è¡¡ï¼‰
MODEL_FILE = "dnn_model_smote.h5"
LABEL_ENCODER_FILE = "label_encoder.pkl"
SCALER_FILE = "scaler.pkl"
CONFUSION_MATRIX_PNG = "confusion_matrix_smote.png"

# === è¼‰å…¥è³‡æ–™ ===
print(f"ğŸ“¥ è¼‰å…¥åŸå§‹è³‡æ–™ï¼š{DATA_FILE}")
df = pd.read_csv(DATA_FILE)
X = df.drop('Label', axis=1)
y_raw = df['Label']

# === Label ç·¨ç¢¼ ===
le = LabelEncoder()
y = le.fit_transform(y_raw)
joblib.dump(le, LABEL_ENCODER_FILE)
print("âœ… LabelEncoder å·²å„²å­˜")

# === åˆ‡åˆ†è¨“ç·´èˆ‡æ¸¬è©¦è³‡æ–™ï¼ˆæ¸¬è©¦é›†ä¿æŒçœŸå¯¦åˆ†å¸ƒï¼‰===
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42)

# === ç‰¹å¾µæ¨™æº–åŒ–å™¨ï¼ˆfit æ–¼è¨“ç·´é›†ï¼‰===
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
joblib.dump(scaler, SCALER_FILE)
print("âœ… æ¨™æº–åŒ–å™¨å·²å„²å­˜")

# === å°è¨“ç·´é›†åš SMOTE ===
print("ğŸ” å¥—ç”¨ SMOTE æ–¼è¨“ç·´é›†...")
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)
print(f"è¨“ç·´é›†æ¨£æœ¬æ•¸ï¼š{len(X_train_res)}ï¼ˆåŸï¼š{len(X_train)}ï¼‰")

# === One-hot ç·¨ç¢¼ ===
num_classes = len(le.classes_)
y_train_cat = to_categorical(y_train_res, num_classes)
y_test_cat = to_categorical(y_test, num_classes)

# === å»ºç«‹ DNN æ¨¡å‹ ===
model = Sequential([
    Dense(256, input_dim=X.shape[1], activation='relu'),
    Dropout(0.3),
    Dense(128, activation='relu'),
    Dropout(0.2),
    Dense(num_classes, activation='softmax')
])
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# === è¨“ç·´æ¨¡å‹ ===
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
print("ğŸš€ é–‹å§‹è¨“ç·´æ¨¡å‹ï¼ˆä½¿ç”¨ SMOTE å¹³è¡¡å¾Œçš„è¨“ç·´é›†ï¼‰...")
model.fit(X_train_res, y_train_cat,
          epochs=20,
          batch_size=1024,
          validation_split=0.1,
          callbacks=[early_stop],
          verbose=2)

# === æ¸¬è©¦èˆ‡åˆ†é¡å ±å‘Š ===
y_pred_prob = model.predict(X_test_scaled)
y_pred_classes = np.argmax(y_pred_prob, axis=1)

target_names = [str(name) for name in le.classes_]
print("\nğŸ“Š æ¸¬è©¦é›†åˆ†é¡å ±å‘Šï¼š")
print(classification_report(y_test, y_pred_classes, target_names=target_names, zero_division=0))

# === æ··æ·†çŸ©é™£åœ– ===
cm = confusion_matrix(y_test, y_pred_classes)
plt.figure(figsize=(18, 14))
sns.heatmap(cm, cmap='Blues', xticklabels=target_names, yticklabels=target_names)
plt.title("Confusion Matrix (Test Set, SMOTE Training)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.savefig(CONFUSION_MATRIX_PNG)
print(f"ğŸ–¼ï¸ æ¸¬è©¦æ··æ·†çŸ©é™£å·²å„²å­˜ç‚º {CONFUSION_MATRIX_PNG}")

# === å„²å­˜æ¨¡å‹ ===
model.save(MODEL_FILE)
print(f"âœ… æ¨¡å‹å·²å„²å­˜ç‚º {MODEL_FILE}")
